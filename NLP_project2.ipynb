{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8aeba8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcd2f126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = pipeline(\"text-generation\", model= \"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3c6aa8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"i want to get the full marks\"\n",
    "num_documents = 3\n",
    "generated_documents = []\n",
    "\n",
    "for _ in range(num_documents):\n",
    "    result = model(sentence, do_sample=True, top_k=50, temperature=0.9, max_length=50)\n",
    "    generated_text = result[0]['generated_text']\n",
    "    generated_documents.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65fa05a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"i want to get the full marks and to be able to run and go when the ball goes with the ball in the air but this year we didn't have the balls at the right time and we had to find something we could throw the ball against\",\n",
       " 'i want to get the full marks.\"\\n\\nThe first time a man in his late 20s and early 30s was arrested following an altercation in L\\'Enfant Plaza at a protest outside the Paris office of Vogue, a global brand',\n",
       " 'i want to get the full marks of his team for the tournament, the winner will be announced at the top of the final page. I like to give a full list of all the players that are available in the game (I have a nice gallery']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e545234d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Document 1:\n",
      "i want to get the full marks and to be able to run and go when the ball goes with the ball in the air but this year we didn't have the balls at the right time and we had to find something we could throw the ball against\n",
      "Generated Document 2:\n",
      "i want to get the full marks.\"\n",
      "\n",
      "The first time a man in his late 20s and early 30s was arrested following an altercation in L'Enfant Plaza at a protest outside the Paris office of Vogue, a global brand\n",
      "Generated Document 3:\n",
      "i want to get the full marks of his team for the tournament, the winner will be announced at the top of the final page. I like to give a full list of all the players that are available in the game (I have a nice gallery\n"
     ]
    }
   ],
   "source": [
    "# Print the generated documents\n",
    "for i, document in enumerate(generated_documents):\n",
    "    print(f\"Generated Document {i+1}:\")\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee24c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove non-alphanumeric characters and extra whitespaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word,pos ='v') for word in tokens]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54f99a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_text = []\n",
    "for doc in generated_documents:\n",
    "    document = preprocess_text(doc)\n",
    "    preprocessed_text.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa3c0c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['want',\n",
       "  'get',\n",
       "  'full',\n",
       "  'mark',\n",
       "  'able',\n",
       "  'run',\n",
       "  'go',\n",
       "  'ball',\n",
       "  'go',\n",
       "  'ball',\n",
       "  'air',\n",
       "  'year',\n",
       "  'ball',\n",
       "  'right',\n",
       "  'time',\n",
       "  'find',\n",
       "  'something',\n",
       "  'could',\n",
       "  'throw',\n",
       "  'ball'],\n",
       " ['want',\n",
       "  'get',\n",
       "  'full',\n",
       "  'mark',\n",
       "  'first',\n",
       "  'time',\n",
       "  'man',\n",
       "  'late',\n",
       "  'early',\n",
       "  'arrest',\n",
       "  'follow',\n",
       "  'altercation',\n",
       "  'l',\n",
       "  'enfant',\n",
       "  'plaza',\n",
       "  'protest',\n",
       "  'outside',\n",
       "  'paris',\n",
       "  'office',\n",
       "  'vogue',\n",
       "  'global',\n",
       "  'brand'],\n",
       " ['want',\n",
       "  'get',\n",
       "  'full',\n",
       "  'mark',\n",
       "  'team',\n",
       "  'tournament',\n",
       "  'winner',\n",
       "  'announce',\n",
       "  'top',\n",
       "  'final',\n",
       "  'page',\n",
       "  'like',\n",
       "  'give',\n",
       "  'full',\n",
       "  'list',\n",
       "  'players',\n",
       "  'available',\n",
       "  'game',\n",
       "  'nice',\n",
       "  'gallery']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95012488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['want', 'get', 'full', 'mark', 'able', 'run', 'ball', 'ball', 'air', 'year', 'ball', 'right', 'time', 'find', 'something', 'could', 'throw', 'ball'], ['want', 'get', 'full', 'mark', 'first', 'time', 'man', 'late', 'early', 'arrest', 'follow', 'altercation', 'enfant', 'plaza', 'protest', 'outside', 'paris', 'office', 'vogue', 'global', 'brand'], ['want', 'get', 'full', 'mark', 'team', 'tournament', 'winner', 'announce', 'top', 'final', 'page', 'like', 'give', 'full', 'list', 'players', 'available', 'game', 'nice', 'gallery']]\n"
     ]
    }
   ],
   "source": [
    "# delete tokens with length less than 3\n",
    "last_list= []\n",
    "\n",
    "for list_ in preprocessed_text:\n",
    "    l = []\n",
    "    for token in list_: \n",
    "        if len(token)>=3:\n",
    "            l.append (token)\n",
    "    last_list.append(l)\n",
    "\n",
    "print(last_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e29842d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get unique words\n",
    "def get_unique_words(tokens):\n",
    "    return set(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ceed288",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = []\n",
    "for doc in last_list:\n",
    "    document = get_unique_words(doc)\n",
    "    unique_words.append(list(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89f91057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['could',\n",
       "  'able',\n",
       "  'ball',\n",
       "  'year',\n",
       "  'mark',\n",
       "  'air',\n",
       "  'run',\n",
       "  'time',\n",
       "  'something',\n",
       "  'throw',\n",
       "  'right',\n",
       "  'full',\n",
       "  'find',\n",
       "  'want',\n",
       "  'get'],\n",
       " ['man',\n",
       "  'late',\n",
       "  'brand',\n",
       "  'mark',\n",
       "  'protest',\n",
       "  'first',\n",
       "  'altercation',\n",
       "  'get',\n",
       "  'global',\n",
       "  'paris',\n",
       "  'arrest',\n",
       "  'enfant',\n",
       "  'outside',\n",
       "  'follow',\n",
       "  'full',\n",
       "  'plaza',\n",
       "  'office',\n",
       "  'early',\n",
       "  'time',\n",
       "  'vogue',\n",
       "  'want'],\n",
       " ['like',\n",
       "  'page',\n",
       "  'announce',\n",
       "  'give',\n",
       "  'players',\n",
       "  'tournament',\n",
       "  'game',\n",
       "  'final',\n",
       "  'mark',\n",
       "  'top',\n",
       "  'available',\n",
       "  'get',\n",
       "  'team',\n",
       "  'full',\n",
       "  'want',\n",
       "  'list',\n",
       "  'nice',\n",
       "  'winner',\n",
       "  'gallery']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a63714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "tfidf_matrix = vectorizer.fit_transform(last_list)\n",
    "builtin_results_dataframe = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c8919f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       able       air  altercation  announce    arrest  available      ball  \\\n",
      "0  0.192544  0.192544     0.000000  0.000000  0.000000   0.000000  0.770175   \n",
      "1  0.000000  0.000000     0.235875  0.000000  0.235875   0.000000  0.000000   \n",
      "2  0.000000  0.000000     0.000000  0.239444  0.000000   0.239444  0.000000   \n",
      "\n",
      "      brand     could     early  ...  something      team     throw      time  \\\n",
      "0  0.000000  0.192544  0.000000  ...   0.192544  0.000000  0.192544  0.146435   \n",
      "1  0.235875  0.000000  0.235875  ...   0.000000  0.000000  0.000000  0.179389   \n",
      "2  0.000000  0.000000  0.000000  ...   0.000000  0.239444  0.000000  0.000000   \n",
      "\n",
      "        top  tournament     vogue      want    winner      year  \n",
      "0  0.000000    0.000000  0.000000  0.113720  0.000000  0.192544  \n",
      "1  0.000000    0.000000  0.235875  0.139311  0.000000  0.000000  \n",
      "2  0.239444    0.239444  0.000000  0.141420  0.239444  0.000000  \n",
      "\n",
      "[3 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "print(builtin_results_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3cbe62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of times term t in document / total num of terms in document\n",
    "def calculate_tf(document_words):\n",
    "    tf_document = {}\n",
    "    total_terms = len(document_words)\n",
    "    for term in set(document_words):\n",
    "        tf_document[term] = document_words.count(term) / total_terms\n",
    "    return tf_document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24b0c5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'could': 0.05555555555555555, 'able': 0.05555555555555555, 'ball': 0.2222222222222222, 'year': 0.05555555555555555, 'mark': 0.05555555555555555, 'air': 0.05555555555555555, 'run': 0.05555555555555555, 'time': 0.05555555555555555, 'something': 0.05555555555555555, 'throw': 0.05555555555555555, 'right': 0.05555555555555555, 'full': 0.05555555555555555, 'find': 0.05555555555555555, 'want': 0.05555555555555555, 'get': 0.05555555555555555}\n"
     ]
    }
   ],
   "source": [
    "print(calculate_tf(last_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ece2e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_idf(corpus, term):\n",
    "    total_documents = len(corpus)\n",
    "    document_containing_term = sum([1 for document in corpus if term in document])\n",
    "    if document_containing_term > 0:\n",
    "        return math.log10(total_documents / (document_containing_term+1)) + 1\n",
    "    else:\n",
    "        return 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29c95ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_idf(last_list,\"player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9dce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
